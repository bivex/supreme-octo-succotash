#!/usr/bin/env python3
"""
Business Logic Implementation Checker

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å –ª–æ–≥–∏–∫–∏.
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π, –≤—ã—è–≤–ª—è–µ—Ç
mock –¥–∞–Ω–Ω—ã–µ –∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å.
"""

import os
import re
import ast
import yaml
import json
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional, Any
from dataclasses import dataclass, field
from enum import Enum


class ImplementationStatus(Enum):
    """–°—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞."""
    NOT_IMPLEMENTED = "not_implemented"
    MOCK_IMPLEMENTED = "mock_implemented"
    PARTIALLY_IMPLEMENTED = "partially_implemented"
    FULLY_IMPLEMENTED = "fully_implemented"


@dataclass
class EndpointAnalysis:
    """–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞."""
    path: str
    method: str
    operation_id: Optional[str]
    summary: Optional[str]
    tags: List[str] = field(default_factory=list)
    status: ImplementationStatus = ImplementationStatus.NOT_IMPLEMENTED
    route_file: Optional[str] = None
    handler_function: Optional[str] = None
    mock_patterns: List[str] = field(default_factory=list)
    missing_components: List[str] = field(default_factory=list)
    implementation_notes: List[str] = field(default_factory=list)


@dataclass
class BusinessLogicReport:
    """–û–±—â–∏–π –æ—Ç—á–µ—Ç –æ –±–∏–∑–Ω–µ—Å –ª–æ–≥–∏–∫–µ."""
    total_endpoints: int = 0
    implemented_endpoints: int = 0
    mock_endpoints: int = 0
    not_implemented_endpoints: int = 0
    partially_implemented_endpoints: int = 0

    endpoints_by_status: Dict[str, List[EndpointAnalysis]] = field(default_factory=dict)
    endpoints_by_tag: Dict[str, List[EndpointAnalysis]] = field(default_factory=dict)

    critical_missing_features: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)


class BusinessLogicChecker:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å –ª–æ–≥–∏–∫–∏ API."""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.openapi_path = project_root / "openapi.yaml"
        self.routes_dir = project_root / "src" / "presentation" / "routes"

        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã mock –¥–∞–Ω–Ω—ã—Ö
        self.mock_patterns = [
            # –ë–∞–∑–æ–≤—ã–µ mock –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            r'mock.*response',
            r'fake.*data',
            r'dummy.*result',
            r'test.*response',
            r'hardcoded.*data',
            r'static.*response',

            # JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å hardcoded –¥–∞–Ω–Ω—ã–º–∏
            r'"status":\s*"success"',
            r'"status":\s*"ok"',
            r'"status":\s*"error"',
            r'"message":\s*"[^*]*successfully[^"]*"',
            r'"message":\s*"[^*]*success[^"]*"',

            # –ú–µ—Ç—Ä–∏–∫–∏ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏
            r'"average_ltv":\s*\d+\.\d+',
            r'"total_customers":\s*\d+',
            r'"conversion_rate":\s*\d+\.\d+',
            r'"clicks":\s*\d+',
            r'"impressions":\s*\d+',

            # –ú–∞—Å—Å–∏–≤—ã —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            r'"campaigns":\s*\[',
            r'"leads":\s*\[',
            r'"clicks":\s*\[',
            r'"events":\s*\[',

            # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            r'"lead_id":\s*".*"',
            r'"campaign_id":\s*".*"',
            r'"click_id":\s*".*"',

            # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –¥–æ–º–µ–Ω—ã
            r'retention.*campaigns.*mock',
            r'welcome.*back.*campaign',
            r'personalized.*message.*segment',

            # –û–±—â–∏–µ mock –æ—Ç–≤–µ—Ç—ã
            r'return\s*\{[^}]*"status":\s*"success"[^}]*\}',
            r'return\s*\{[^}]*"message":\s*"[^"]*success[^"]*"[^}]*\}',

            # Empty implementations
            r'return\s*\{\s*\}',
            r'return\s*None',
            r'pass\s*$',
        ]

        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        self.real_implementation_patterns = [
            # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            r'\.save\(',
            r'\.find_by_',
            r'\.get_by_',
            r'\.find_all\(',
            r'\.count_by_',
            r'\.delete\(',
            r'\.update\(',
            r'\.create\(',

            # –°–µ—Ä–≤–∏—Å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            r'\.calculate_',
            r'\.validate_',
            r'\.process_',
            r'\.analyze_',
            r'\.generate_',
            r'\.enrich_',
            r'\.filter_',
            r'\.aggregate_',

            # –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            r'repository\.',
            r'service\.',
            r'handler\.',
            r'factory\.',
            r'manager\.',

            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            r'await\s+\w+\.',
            r'async\s+def',

            # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
            r'if\s+.*repository',
            r'for\s+.*in\s+.*repository',
            r'with\s+.*repository',

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
            r'try:',
            r'except\s+\w+:',
            r'raise\s+\w+',

            # –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
            r'json\.dumps',
            r'json\.loads',
            r'\.to_dict\(\)',
            r'\.from_dict\(',
            r'\.serialize',
            r'\.deserialize',

            # HTTP –∫–ª–∏–µ–Ω—Ç—ã –∏ –≤–Ω–µ—à–Ω–∏–µ API
            r'requests\.',
            r'httpx\.',
            r'aiohttp\.',

            # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
            r'\.execute\(',
            r'\.commit\(\)',
            r'\.rollback\(\)',
            r'SELECT\s+.*FROM',
            r'INSERT\s+INTO',
            r'UPDATE\s+.*SET',
            r'DELETE\s+FROM',

            # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            r'CampaignRepository',
            r'AnalyticsRepository',
            r'EventRepository',
            r'ConversionRepository',
            r'LandingPageRepository',
            r'OfferRepository',
            r'CampaignService',
            r'AnalyticsService',
            r'EventService',

            # CQRS –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            r'Query\(',
            r'Command\(',
            r'Handler\(',
            r'QueryHandler',
            r'CommandHandler',
            r'GetCampaignQuery',
            r'GetCampaignAnalyticsQuery',
            r'GetCampaignLandingPagesQuery',
            r'GetCampaignOffersQuery',

            # Dependency Injection –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            r'container\.',
            r'_container\.',
            r'get_campaign_repository',
            r'get_analytics_repository',
            r'get_event_repository',
            r'get_campaign_handler',
            r'get_analytics_handler',

            # Middleware –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            r'middleware\.',
            r'validate_request',
            r'add_security_headers',

            # Pagination –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            r'page\s*=',
            r'pageSize\s*=',
            r'limit\s*=',
            r'offset\s*=',
            r'pagination',
            r'total_count',
            r'total_pages',

            # Domain –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            r'Campaign\(',
            r'CampaignId\(',
            r'Event\(',
            r'Conversion\(',
            r'Money\(',
            r'DateRange\(',
            r'Analytics\(',

            # Logger –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            r'logger\.',
            r'logger\.error',
            r'logger\.info',
            r'logger\.debug',
            r'traceback\.',

            # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —É—Ç–∏–ª–∏—Ç—ã
            r'money_to_dict',
            r'datetime\.',
            r'date\.',
        ]

    def analyze_business_logic(self) -> BusinessLogicReport:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –±–∏–∑–Ω–µ—Å –ª–æ–≥–∏–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏."""
        print("üîç –ù–∞—á–∏–Ω–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–∏–∑–Ω–µ—Å –ª–æ–≥–∏–∫–∏ API...")
        print("=" * 60)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é
        openapi_spec = self._load_openapi_spec()
        if not openapi_spec:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é")
            return BusinessLogicReport()

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
        endpoints = self._extract_endpoints_from_openapi(openapi_spec)
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(endpoints)} —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤ –≤ OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ routes
        route_files = self._find_route_files()
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(route_files)} route —Ñ–∞–π–ª–æ–≤")

        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å OpenAPI
        spec_freshness = self._analyze_openapi_freshness(openapi_spec, route_files)
        if spec_freshness['issues']:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–±–ª–µ–º—ã —Å –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å—é OpenAPI: {len(spec_freshness['issues'])}")

        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞
        print("\nüîé –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º endpoints...")
        analyzed_endpoints = []
        processed_count = 0

        for endpoint in endpoints:
            analyzed_endpoint = self._analyze_endpoint(endpoint, route_files)
            analyzed_endpoints.append(analyzed_endpoint)

            processed_count += 1
            if processed_count % 10 == 0:
                print(f"  ‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count}/{len(endpoints)} endpoints")

        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(analyzed_endpoints)} endpoints")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
        report = self._generate_report(analyzed_endpoints)

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É
        report = self._enhance_report_with_advanced_analytics(report, analyzed_endpoints, spec_freshness)

        return report

    def _analyze_openapi_freshness(self, spec: Dict, route_files: Dict[str, Path]) -> Dict[str, List[str]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏."""
        issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–æ–≤—ã–µ route —Ñ–∞–π–ª—ã, –Ω–µ –æ—Ç—Ä–∞–∂–µ–Ω–Ω—ã–µ –≤ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
        spec_paths = set()
        if 'paths' in spec:
            spec_paths = set(spec['paths'].keys())

        route_paths = set()
        for route_file, file_path in route_files.items():
            content = self._read_file_content(file_path)
            if content:
                # –ò—â–µ–º –≤—Å–µ –ø—É—Ç–∏ –≤ route —Ñ–∞–π–ª–µ
                path_patterns = [
                    r"app\.\w+\(\s*['\"]([^'\"]+)['\"]",
                    r"app\.\w+\(\s*f?['\"]([^'\"]+)['\"]"
                ]

                for pattern in path_patterns:
                    matches = re.findall(pattern, content)
                    for match in matches:
                        route_paths.add(match)

        # –ù–∞—Ö–æ–¥–∏–º –Ω–æ–≤—ã–µ –ø—É—Ç–∏
        new_paths = route_paths - spec_paths
        if new_paths:
            issues.append(f"–ù–∞–π–¥–µ–Ω–æ {len(new_paths)} –Ω–æ–≤—ã—Ö –ø—É—Ç–µ–π –Ω–µ –æ—Ç—Ä–∞–∂–µ–Ω–Ω—ã—Ö –≤ OpenAPI")

        return {'issues': issues, 'new_paths': list(new_paths)}

    def _enhance_report_with_advanced_analytics(self, report: BusinessLogicReport, endpoints: List[EndpointAnalysis], spec_freshness: Dict) -> BusinessLogicReport:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –≤ –æ—Ç—á–µ—Ç."""
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–≤–µ–∂–µ—Å—Ç–∏ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
        if spec_freshness['issues']:
            report.critical_missing_features.extend([
                f"OpenAPI Spec Issue: {issue}" for issue in spec_freshness['issues']
            ])

        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_metrics = self._calculate_quality_metrics(endpoints)
        if quality_metrics:
            report.recommendations.extend([
                f"üìä –ö–∞—á–µ—Å—Ç–≤–æ: {metric}" for metric in quality_metrics
            ])

        return report

    def _calculate_quality_metrics(self, endpoints: List[EndpointAnalysis]) -> List[str]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏."""
        metrics = []

        implemented_endpoints = [e for e in endpoints if e.status == ImplementationStatus.FULLY_IMPLEMENTED]

        if implemented_endpoints:
            # –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞ endpoint
            avg_components = sum(len(e.implementation_notes) for e in implemented_endpoints) / len(implemented_endpoints)
            metrics.append(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {avg_components:.1f}")

            # –ü—Ä–æ—Ü–µ–Ω—Ç endpoints —Å error handling
            with_error_handling = sum(1 for e in implemented_endpoints
                                    if any('error' in note.lower() for note in e.implementation_notes))
            error_handling_pct = (with_error_handling / len(implemented_endpoints)) * 100
            metrics.append(f"Error handling coverage: {error_handling_pct:.1f}%")

            # –ü—Ä–æ—Ü–µ–Ω—Ç endpoints —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
            with_validation = sum(1 for e in implemented_endpoints
                                if any('valid' in note.lower() for note in e.implementation_notes))
            validation_pct = (with_validation / len(implemented_endpoints)) * 100
            metrics.append(f"Validation coverage: {validation_pct:.1f}%")

        return metrics

    def _load_openapi_spec(self) -> Optional[Dict]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é."""
        try:
            with open(self.openapi_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            return None

    def _extract_endpoints_from_openapi(self, spec: Dict) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –∏–∑ OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏."""
        endpoints = []

        if 'paths' not in spec:
            return endpoints

        for path, path_item in spec['paths'].items():
            for method, operation in path_item.items():
                if method.upper() not in ['GET', 'POST', 'PUT', 'DELETE', 'PATCH']:
                    continue

                endpoint = {
                    'path': path,
                    'method': method.upper(),
                    'operation_id': operation.get('operationId'),
                    'summary': operation.get('summary'),
                    'description': operation.get('description'),
                    'tags': operation.get('tags', []),
                    'responses': operation.get('responses', {})
                }
                endpoints.append(endpoint)

        return endpoints

    def _find_route_files(self) -> Dict[str, Path]:
        """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ route —Ñ–∞–π–ª—ã."""
        route_files = {}
        if not self.routes_dir.exists():
            return route_files

        for file_path in self.routes_dir.glob("*.py"):
            if file_path.name != "__init__.py":
                route_files[file_path.stem] = file_path

        return route_files

    def _analyze_endpoint(self, endpoint: Dict, route_files: Dict[str, Path]) -> EndpointAnalysis:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç."""
        analysis = EndpointAnalysis(
            path=endpoint['path'],
            method=endpoint['method'],
            operation_id=endpoint.get('operation_id'),
            summary=endpoint.get('summary'),
            tags=endpoint.get('tags', [])
        )

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π route —Ñ–∞–π–ª
        route_file = self._find_matching_route_file(endpoint, route_files)
        if not route_file:
            analysis.status = ImplementationStatus.NOT_IMPLEMENTED
            analysis.missing_components.append("Route file not found")
            return analysis

        analysis.route_file = route_file

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ route —Ñ–∞–π–ª–∞
        route_content = self._read_file_content(route_files[route_file])
        if not route_content:
            analysis.status = ImplementationStatus.NOT_IMPLEMENTED
            analysis.missing_components.append("Route file content not readable")
            return analysis

        # –ò—â–µ–º —Ñ—É–Ω–∫—Ü–∏—é-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        handler_function = self._find_handler_function(endpoint, route_content)
        analysis.handler_function = handler_function

        if handler_function:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
            status, mock_patterns, missing_components, notes = self._analyze_handler_implementation(
                handler_function, route_content
            )
            analysis.status = status
            analysis.mock_patterns = mock_patterns
            analysis.missing_components = missing_components
            analysis.implementation_notes = notes
        else:
            # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Å—å —Ñ–∞–π–ª –Ω–∞ mock –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            status, mock_patterns, missing_components, notes = self._analyze_file_implementation(route_content)
            analysis.status = status
            analysis.mock_patterns = mock_patterns
            analysis.missing_components = missing_components + ["Handler function not found"]
            analysis.implementation_notes = notes

        analysis.status = status
        analysis.mock_patterns = mock_patterns
        analysis.missing_components = missing_components
        analysis.implementation_notes = notes

        return analysis

    def _find_matching_route_file(self, endpoint: Dict, route_files: Dict[str, Path]) -> Optional[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π route —Ñ–∞–π–ª –¥–ª—è —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º."""
        path = endpoint['path'].lower()
        method = endpoint['method'].lower()

        # –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –ø—É—Ç–∏
        path_mappings = {
            # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–æ–º–µ–Ω—ã
            'campaign': 'campaign_routes',
            'campaigns': 'campaign_routes',
            'click': 'click_routes',
            'clicks': 'click_routes',
            'analytics': 'analytics_routes',
            'fraud': 'fraud_routes',
            'webhook': 'webhook_routes',
            'webhooks': 'webhook_routes',
            'event': 'event_routes',
            'events': 'event_routes',
            'conversion': 'conversion_routes',
            'conversions': 'conversion_routes',
            'postback': 'postback_routes',
            'postbacks': 'postback_routes',
            'goal': 'goal_routes',
            'goals': 'goal_routes',
            'journey': 'journey_routes',
            'journeys': 'journey_routes',
            'ltv': 'ltv_routes',
            'retention': 'retention_routes',
            'form': 'form_routes',
            'forms': 'form_routes',
            'bulk': 'bulk_operations_routes',
            'system': 'system_routes',
            'cache': 'system_routes',
            'health': 'system_routes',
            'status': 'system_routes',
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –ø—É—Ç–∏
        for keyword, route_file in path_mappings.items():
            if keyword in path and route_file in route_files:
                return route_file

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—É—Ç–∏ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        path_parts = [part for part in path.strip('/').split('/') if part and not part.startswith('{')]
        path_keywords = set()

        for part in path_parts:
            # –†–∞–∑–±–∏–≤–∞–µ–º —Å–æ—Å—Ç–∞–≤–Ω—ã–µ —Å–ª–æ–≤–∞
            words = re.findall(r'[a-zA-Z]+', part.lower())
            path_keywords.update(words)

        # –ò—Å–∫–ª—é—á–∞–µ–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞
        exclude_words = {'v1', 'api', 'id', 'ids', 'list', 'get', 'create', 'update', 'delete'}
        path_keywords -= exclude_words

        if not path_keywords:
            return None

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π route —Ñ–∞–π–ª
        best_match = None
        best_score = 0
        best_confidence = 0

        for route_name in route_files.keys():
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∏–º–µ–Ω–∏ route —Ñ–∞–π–ª–∞
            route_keywords = set()
            route_base = route_name.replace('_routes', '')

            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            words = re.findall(r'[a-zA-Z]+', route_base.lower())
            route_keywords.update(words)

            # –í—ã—á–∏—Å–ª—è–µ–º –æ—Ü–µ–Ω–∫—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            common_keywords = path_keywords & route_keywords
            score = len(common_keywords)

            # –ë–æ–Ω—É—Å –∑–∞ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
            if path_keywords and route_keywords and list(path_keywords)[0] in route_keywords:
                score += 2

            # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            if 'system' in route_keywords and not any(word in path for word in ['health', 'cache', 'status']):
                score -= 1

            # Confidence - –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            total_keywords = len(path_keywords | route_keywords)
            confidence = score / max(total_keywords, 1) if total_keywords > 0 else 0

            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if score > best_score or (score == best_score and confidence > best_confidence):
                best_score = score
                best_confidence = confidence
                best_match = route_name

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∞
        return best_match if best_confidence > 0.2 and best_score > 0 else None

    def _read_file_content(self, file_path: Path) -> Optional[str]:
        """–ß–∏—Ç–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return None

    def _find_handler_function(self, endpoint: Dict, route_content: str) -> Optional[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Ñ—É–Ω–∫—Ü–∏—é-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º."""
        method = endpoint['method'].lower()
        path = endpoint['path']

        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –ø—É—Ç–∏
        escaped_path = re.escape(path)

        # –ë–æ–ª–µ–µ –≥–∏–±–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –º–∞—Ä—à—Ä—É—Ç–æ–≤
        patterns = [
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: app.method('path', handler)
            rf"app\.{method}\(\s*['\"]{escaped_path}['\"]\s*,\s*(\w+)\s*\)",

            # –° –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –≤ –ø—É—Ç–∏: app.method('path' + var, handler)
            rf"app\.{method}\(\s*['\"]{escaped_path}\s*\+\s*[^,]+,\s*(\w+)\s*\)",

            # –° —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å—Ç—Ä–æ–∫: app.method(f'path', handler)
            rf"app\.{method}\(\s*f?['\"]{escaped_path}['\"],\s*(\w+)\s*\)",

            # –° –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: app.method('path', handler, ...)
            rf"app\.{method}\(\s*['\"]{escaped_path}['\"]\s*,\s*(\w+)\s*[,)]",

            # –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            rf"app\.{method}\(\s*['\"]{escaped_path}['\"]\s*,\s*\n?\s*(\w+)\s*\)",
        ]

        # –ò—â–µ–º –ø–æ –≤—Å–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        for pattern in patterns:
            match = re.search(pattern, route_content, re.MULTILINE | re.DOTALL)
            if match:
                function_name = match.group(1)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–º—è —Ñ—É–Ω–∫—Ü–∏–∏ (–Ω–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è)
                if self._is_function_name(function_name, route_content):
                    return function_name

        # Fallback: –∏—â–µ–º —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —ç—Ç–æ—Ç –ø—É—Ç—å
        # –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ –∏–º–µ–Ω
        return self._find_handler_by_context(endpoint, route_content)

    def _is_function_name(self, name: str, content: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∏–º–µ–Ω–µ–º —Ñ—É–Ω–∫—Ü–∏–∏."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        if name in ['None', 'True', 'False', 'self']:
            return False

        # –ò—â–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å —ç—Ç–∏–º –∏–º–µ–Ω–µ–º
        function_pattern = rf"def\s+{re.escape(name)}\s*\("
        return bool(re.search(function_pattern, content))

    def _find_handler_by_context(self, endpoint: Dict, route_content: str) -> Optional[str]:
        """–ò—â–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∏–º–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏–π)."""
        path = endpoint['path'].lower()
        method = endpoint['method'].lower()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –ø—É—Ç–∏
        path_keywords = re.findall(r'[a-zA-Z]+', path)
        path_keywords = [kw.lower() for kw in path_keywords if len(kw) > 2 and kw not in ['api', 'v1']]

        # –ò—â–µ–º —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —ç—Ç–æ—Ç endpoint
        function_pattern = r"def\s+(\w+)\s*\("
        functions = re.findall(function_pattern, route_content)

        best_match = None
        best_score = 0

        for func_name in functions:
            score = 0

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º—è —Ñ—É–Ω–∫—Ü–∏–∏
            func_lower = func_name.lower()
            if any(keyword in func_lower for keyword in path_keywords):
                score += 2

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–µ—Ä–µ–¥ —Ñ—É–Ω–∫—Ü–∏–µ–π
            func_start = route_content.find(f"def {func_name}")
            if func_start > 0:
                # –ò—â–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö 5 —Å—Ç—Ä–æ–∫–∞—Ö
                lines_before = route_content[:func_start].split('\n')[-5:]
                comment_text = '\n'.join(lines_before).lower()

                if any(keyword in comment_text for keyword in path_keywords):
                    score += 1

                if method in comment_text:
                    score += 1

            if score > best_score:
                best_score = score
                best_match = func_name

        return best_match if best_score > 1 else None

    def _analyze_handler_implementation(self, handler_function: str, route_content: str) -> Tuple[ImplementationStatus, List[str], List[str], List[str]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é —Ñ—É–Ω–∫—Ü–∏–∏-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º."""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ –∫–æ–¥–∞ —Å —É—á–µ—Ç–æ–º –æ—Ç—Å—Ç—É–ø–æ–≤
        function_pattern = rf"def\s+{re.escape(handler_function)}\s*\([^)]*\):(.*?)(?=\n\S|\n\s*def|\n\s*@|\n\s*class|\Z)"
        match = re.search(function_pattern, route_content, re.DOTALL)

        if not match:
            return ImplementationStatus.NOT_IMPLEMENTED, [], ["Function definition not found"], []

        function_body = match.group(1)

        # –û—á–∏—â–∞–µ–º —Ç–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        cleaned_body = self._clean_function_body(function_body)

        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        analysis_result = self._comprehensive_implementation_analysis(cleaned_body)

        return analysis_result

    def _clean_function_body(self, body: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."""
        # –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        body = re.sub(r'#.*$', '', body, flags=re.MULTILINE)
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        body = re.sub(r'\n\s*\n', '\n', body)
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        body = body.strip()
        return body

    def _comprehensive_implementation_analysis(self, function_body: str) -> Tuple[ImplementationStatus, List[str], List[str], List[str]]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏."""
        mock_patterns_found = []
        real_patterns_found = []
        missing_components = []
        notes = []

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        has_business_logic = False
        has_data_access = False
        has_error_handling = False
        has_validation = False
        has_external_calls = False

        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ mock –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern in self.mock_patterns:
            if re.search(pattern, function_body, re.IGNORECASE | re.DOTALL):
                mock_patterns_found.append(pattern)

        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        for pattern in self.real_implementation_patterns:
            if re.search(pattern, function_body, re.DOTALL):
                real_patterns_found.append(pattern)
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
                if any(word in pattern for word in ['repository', 'save', 'find_by', 'get_by', 'delete', 'update']):
                    has_data_access = True
                if any(word in pattern for word in ['service', 'handler', 'calculate', 'process', 'validate']):
                    has_business_logic = True
                if any(word in pattern for word in ['try:', 'except', 'raise']):
                    has_error_handling = True
                if any(word in pattern for word in ['requests', 'httpx', 'aiohttp']):
                    has_external_calls = True

        # 3. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–¥–∞
        lines = [line.strip() for line in function_body.split('\n') if line.strip()]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        if any('validate' in line.lower() or 'check' in line.lower() for line in lines):
            has_validation = True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—É—Å—Ç—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é
        if not lines or all(line in ['pass', '...', 'return None', 'return {}'] for line in lines):
            return ImplementationStatus.NOT_IMPLEMENTED, [], ["Empty or trivial implementation"], []

        # 4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        if mock_patterns_found and not real_patterns_found:
            # –¢–æ–ª—å–∫–æ mock –¥–∞–Ω–Ω—ã–µ
            status = ImplementationStatus.MOCK_IMPLEMENTED
            notes.append("Contains only mock/stub data")
            missing_components.append("Replace mock data with real business logic")

        elif real_patterns_found and not mock_patterns_found:
            # –¢–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
            if has_business_logic and has_data_access:
                status = ImplementationStatus.FULLY_IMPLEMENTED
                notes.append("Complete business logic implementation")
                if has_error_handling:
                    notes.append("Includes error handling")
                if has_validation:
                    notes.append("Includes input validation")
                if has_external_calls:
                    notes.append("Includes external API calls")
            elif has_business_logic or has_data_access:
                status = ImplementationStatus.FULLY_IMPLEMENTED
                notes.append("Basic business logic implementation")
            else:
                status = ImplementationStatus.PARTIALLY_IMPLEMENTED
                notes.append("Contains some real patterns but incomplete")

        elif real_patterns_found and mock_patterns_found:
            # –°–º–µ—à–∞–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
            status = ImplementationStatus.PARTIALLY_IMPLEMENTED
            notes.append("Mixed mock and real implementation")
            notes.append(f"Found {len(real_patterns_found)} real patterns, {len(mock_patterns_found)} mock patterns")

            if has_business_logic and has_data_access:
                notes.append("Has core business logic components")
            else:
                missing_components.append("Core business logic components missing")

        else:
            # –ù–µ—Ç —á–µ—Ç–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            status = ImplementationStatus.PARTIALLY_IMPLEMENTED
            missing_components.append("No clear implementation patterns detected")
            notes.append("Requires manual review")

        return status, mock_patterns_found, missing_components, notes

    def _analyze_file_implementation(self, file_content: str) -> Tuple[ImplementationStatus, List[str], List[str], List[str]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞."""
        mock_patterns_found = []
        real_patterns_found = []
        missing_components = []
        notes = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ mock –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤–æ –≤—Å–µ–º —Ñ–∞–π–ª–µ
        for pattern in self.mock_patterns:
            if re.search(pattern, file_content, re.IGNORECASE | re.DOTALL):
                mock_patterns_found.append(pattern)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        for pattern in self.real_implementation_patterns:
            if re.search(pattern, file_content, re.DOTALL):
                real_patterns_found.append(pattern)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        if mock_patterns_found and not real_patterns_found:
            status = ImplementationStatus.MOCK_IMPLEMENTED
            notes.append("File contains mock data patterns")
        elif real_patterns_found:
            status = ImplementationStatus.FULLY_IMPLEMENTED
            notes.append("File contains real business logic")
        else:
            status = ImplementationStatus.NOT_IMPLEMENTED
            missing_components.append("No implementation patterns detected")

        return status, mock_patterns_found, missing_components, notes

    def _generate_report(self, endpoints: List[EndpointAnalysis]) -> BusinessLogicReport:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ —Å—Ç–∞—Ç—É—Å–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏."""
        report = BusinessLogicReport()
        report.total_endpoints = len(endpoints)

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å—Ç–∞—Ç—É—Å—É
        status_groups = {}
        tag_groups = {}

        for endpoint in endpoints:
            # –ü–æ —Å—Ç–∞—Ç—É—Å—É
            status_key = endpoint.status.value
            if status_key not in status_groups:
                status_groups[status_key] = []
            status_groups[status_key].append(endpoint)

            # –ü–æ —Ç–µ–≥–∞–º
            for tag in endpoint.tags:
                if tag not in tag_groups:
                    tag_groups[tag] = []
                tag_groups[tag].append(endpoint)

        report.endpoints_by_status = status_groups
        report.endpoints_by_tag = tag_groups

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        for status, endpoints_list in status_groups.items():
            count = len(endpoints_list)
            if status == ImplementationStatus.FULLY_IMPLEMENTED.value:
                report.implemented_endpoints = count
            elif status == ImplementationStatus.MOCK_IMPLEMENTED.value:
                report.mock_endpoints = count
            elif status == ImplementationStatus.NOT_IMPLEMENTED.value:
                report.not_implemented_endpoints = count
            elif status == ImplementationStatus.PARTIALLY_IMPLEMENTED.value:
                report.partially_implemented_endpoints = count

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report.recommendations = self._generate_recommendations(endpoints)
        report.critical_missing_features = self._identify_critical_missing_features(endpoints)

        return report

    def _generate_recommendations(self, endpoints: List[EndpointAnalysis]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é."""
        recommendations = []

        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
        status_counts = {}
        for endpoint in endpoints:
            status_counts[endpoint.status] = status_counts.get(endpoint.status, 0) + 1

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ mock –¥–∞–Ω–Ω—ã–º
        mock_count = status_counts.get(ImplementationStatus.MOCK_IMPLEMENTED, 0)
        if mock_count > 0:
            recommendations.append(f"üîÑ –ó–∞–º–µ–Ω–∏—Ç—å mock –¥–∞–Ω–Ω—ã–µ –≤ {mock_count} —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞—Ö —Ä–µ–∞–ª—å–Ω–æ–π –±–∏–∑–Ω–µ—Å –ª–æ–≥–∏–∫–æ–π")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –Ω–µ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º endpoint'–∞–º
        not_implemented_count = status_counts.get(ImplementationStatus.NOT_IMPLEMENTED, 0)
        if not_implemented_count > 0:
            recommendations.append(f"üìù –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å {not_implemented_count} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º
        partial_count = status_counts.get(ImplementationStatus.PARTIALLY_IMPLEMENTED, 0)
        if partial_count > 0:
            recommendations.append(f"‚ö° –ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é {partial_count} —á–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤")

        # –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è –¥–æ–º–µ–Ω–æ–≤
        domain_coverage = self._analyze_domain_coverage(endpoints)
        if domain_coverage['missing']:
            recommendations.append(f"üåü –î–æ–±–∞–≤–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–æ–º–µ–Ω—ã: {', '.join(domain_coverage['missing'])}")

        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        quality_issues = self._analyze_implementation_quality(endpoints)
        recommendations.extend(quality_issues)

        # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –ø–æ –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç–∏
        priority_recs = self._prioritize_by_business_value(endpoints)
        recommendations.extend(priority_recs)

        return recommendations

    def _identify_critical_missing_features(self, endpoints: List[EndpointAnalysis]) -> List[str]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏."""
        critical_features = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –±–∏–∑–Ω–µ—Å-—Ñ—É–Ω–∫—Ü–∏–π
        has_campaign_management = any('campaign' in e.tags for e in endpoints)
        has_click_tracking = any('click' in e.tags for e in endpoints)
        has_analytics = any('analytics' in e.tags for e in endpoints)

        if not has_campaign_management:
            critical_features.append("Campaign management endpoints")
        if not has_click_tracking:
            critical_features.append("Click tracking functionality")
        if not has_analytics:
            critical_features.append("Analytics and reporting")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ mock —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö
        critical_mock = [
            e for e in endpoints
            if e.status == ImplementationStatus.MOCK_IMPLEMENTED and
            any(tag in ['campaign', 'analytics', 'security'] for tag in e.tags)
        ]

        if critical_mock:
            critical_features.append(f"Mock —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö: {len(critical_mock)} —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤")

        return critical_features

    def _analyze_domain_coverage(self, endpoints: List[EndpointAnalysis]) -> Dict[str, List[str]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–∫—Ä—ã—Ç–∏–µ –±–∏–∑–Ω–µ—Å-–¥–æ–º–µ–Ω–æ–≤."""
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–≥–∏
        all_tags = set()
        for endpoint in endpoints:
            all_tags.update(endpoint.tags)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–∂–∏–¥–∞–µ–º—ã–µ –¥–æ–º–µ–Ω—ã
        expected_domains = {
            'campaigns': ['campaign', 'campaigns'],
            'analytics': ['analytics'],
            'click_tracking': ['click', 'clicks'],
            'fraud_detection': ['fraud'],
            'webhooks': ['webhook', 'webhooks'],
            'events': ['event', 'events'],
            'conversions': ['conversion', 'conversions'],
            'postbacks': ['postback', 'postbacks'],
            'goals': ['goal', 'goals'],
            'journeys': ['journey', 'journeys'],
            'ltv': ['ltv'],
            'retention': ['retention'],
            'forms': ['form', 'forms'],
            'system': ['system', 'health', 'cache']
        }

        missing_domains = []
        for domain, tags in expected_domains.items():
            if not any(tag in all_tags for tag in tags):
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Ç–∞–µ–º—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                domain_names = {
                    'campaigns': 'Campaign Management',
                    'analytics': 'Analytics & Reporting',
                    'click_tracking': 'Click Tracking',
                    'fraud_detection': 'Fraud Detection',
                    'webhooks': 'Webhooks',
                    'events': 'Event Tracking',
                    'conversions': 'Conversion Tracking',
                    'postbacks': 'Postback System',
                    'goals': 'Goal Management',
                    'journeys': 'User Journey Analytics',
                    'ltv': 'LTV Analysis',
                    'retention': 'Retention Campaigns',
                    'forms': 'Lead Forms',
                    'system': 'System Management'
                }
                missing_domains.append(domain_names.get(domain, domain))

        return {'present': list(all_tags), 'missing': missing_domains}

    def _analyze_implementation_quality(self, endpoints: List[EndpointAnalysis]) -> List[str]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏."""
        issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ error handling
        endpoints_with_error_handling = 0
        endpoints_with_validation = 0

        for endpoint in endpoints:
            if endpoint.status in [ImplementationStatus.FULLY_IMPLEMENTED, ImplementationStatus.PARTIALLY_IMPLEMENTED]:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º implementation_notes –Ω–∞ –Ω–∞–ª–∏—á–∏–µ error handling –∏ validation
                notes_text = ' '.join(endpoint.implementation_notes).lower()
                if 'error' in notes_text or 'exception' in notes_text:
                    endpoints_with_error_handling += 1
                if 'valid' in notes_text or 'check' in notes_text:
                    endpoints_with_validation += 1

        total_implemented = sum(1 for e in endpoints if e.status in [ImplementationStatus.FULLY_IMPLEMENTED, ImplementationStatus.PARTIALLY_IMPLEMENTED])

        if total_implemented > 0:
            error_handling_coverage = (endpoints_with_error_handling / total_implemented) * 100
            validation_coverage = (endpoints_with_validation / total_implemented) * 100

            if error_handling_coverage < 70:
                issues.append(f"‚ö†Ô∏è  –ü–æ–≤—ã—Å–∏—Ç—å –ø–æ–∫—Ä—ã—Ç–∏–µ error handling: {error_handling_coverage:.1f}% (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è >70%)")

            if validation_coverage < 60:
                issues.append(f"üîç –î–æ–±–∞–≤–∏—Ç—å input validation: {validation_coverage:.1f}% (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è >60%)")

        return issues

    def _prioritize_by_business_value(self, endpoints: List[EndpointAnalysis]) -> List[str]:
        """–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ—Ç –∑–∞–¥–∞—á–∏ –ø–æ –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç–∏."""
        priorities = []

        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ endpoints –±–µ–∑ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        critical_endpoints = [
            e for e in endpoints
            if e.status != ImplementationStatus.FULLY_IMPLEMENTED and
            any(tag in ['campaign', 'analytics', 'fraud', 'security'] for tag in e.tags)
        ]

        if critical_endpoints:
            priorities.append(f"üö® –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å {len(critical_endpoints)} –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ endpoints")

        # Endpoints —Å –≤—ã—Å–æ–∫–∏–º —Ç—Ä–∞—Ñ–∏–∫–æ–º (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—É—Ç–∏)
        high_traffic_patterns = ['/campaigns', '/click', '/analytics', '/health']
        high_traffic_endpoints = [
            e for e in endpoints
            if any(pattern in e.path for pattern in high_traffic_patterns) and
            e.status != ImplementationStatus.FULLY_IMPLEMENTED
        ]

        if high_traffic_endpoints:
            priorities.append(f"‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –£–ª—É—á—à–∏—Ç—å {len(high_traffic_endpoints)} –≤—ã—Å–æ–∫–æ–Ω–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö endpoints")

        return priorities


def print_report(report: BusinessLogicReport):
    """–í—ã–≤–æ–¥–∏—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å."""
    print("\n" + "="*90)
    print("üìä –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –û–¢–ß–ï–¢ –û –†–ï–ê–õ–ò–ó–ê–¶–ò–ò –ë–ò–ó–ù–ï–° –õ–û–ì–ò–ö–ò API")
    print("="*90)

    # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
    print(f"\nüìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"  –í—Å–µ–≥–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤: {report.total_endpoints}")

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
    implemented_pct = (report.implemented_endpoints / report.total_endpoints) * 100 if report.total_endpoints > 0 else 0
    mock_pct = (report.mock_endpoints / report.total_endpoints) * 100 if report.total_endpoints > 0 else 0
    partial_pct = (report.partially_implemented_endpoints / report.total_endpoints) * 100 if report.total_endpoints > 0 else 0
    not_impl_pct = (report.not_implemented_endpoints / report.total_endpoints) * 100 if report.total_endpoints > 0 else 0

    print(f"  ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ: {report.implemented_endpoints} ({implemented_pct:.1f}%)")
    print(f"  ‚ö†Ô∏è  Mock –¥–∞–Ω–Ω—ã–µ: {report.mock_endpoints} ({mock_pct:.1f}%)")
    print(f"  üîÑ –ß–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ: {report.partially_implemented_endpoints} ({partial_pct:.1f}%)")
    print(f"  ‚ùå –ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ: {report.not_implemented_endpoints} ({not_impl_pct:.1f}%)")

    # –°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞
    if implemented_pct >= 95:
        print(f"\nüéâ –°–¢–ê–¢–£–° –ü–†–û–ï–ö–¢–ê: –ü–û–õ–ù–û–°–¢–¨–Æ –ì–û–¢–û–í –ö –ü–†–û–î–ê–ö–®–ï–ù–£!")
    elif implemented_pct >= 80:
        print(f"\n‚ö° –°–¢–ê–¢–£–° –ü–†–û–ï–ö–¢–ê: –ì–û–¢–û–í –ö –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Æ")
    else:
        print(f"\nüöß –°–¢–ê–¢–£–° –ü–†–û–ï–ö–¢–ê: –¢–†–ï–ë–£–ï–¢ –î–û–†–ê–ë–û–¢–ö–ò")

    if report.endpoints_by_status:
        print(f"\nüîç –ü–û–î–†–û–ë–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–û –°–¢–ê–¢–£–°–£:")

        for status in ['fully_implemented', 'partially_implemented', 'mock_implemented', 'not_implemented']:
            if status in report.endpoints_by_status:
                endpoints = report.endpoints_by_status[status]
                status_name = {
                    'fully_implemented': '‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ',
                    'mock_implemented': '‚ö†Ô∏è  Mock –¥–∞–Ω–Ω—ã–µ',
                    'partially_implemented': 'üîÑ –ß–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ',
                    'not_implemented': '‚ùå –ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ'
                }.get(status, status)

                print(f"\n  {status_name} ({len(endpoints)} —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤):")

                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–µ–≥–∞–º –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±–∑–æ—Ä–∞
                tag_groups = {}
                for endpoint in endpoints:
                    primary_tag = endpoint.tags[0] if endpoint.tags else 'other'
                    if primary_tag not in tag_groups:
                        tag_groups[primary_tag] = []
                    tag_groups[primary_tag].append(endpoint)

                for tag, tag_endpoints in tag_groups.items():
                    print(f"    üìÅ {tag.title()}: {len(tag_endpoints)} endpoints")
                    for endpoint in tag_endpoints[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –∏–∑ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
                        print(f"      ‚Ä¢ {endpoint.method} {endpoint.path}")
                        if endpoint.missing_components and status != 'fully_implemented':
                            print(f"        ‚ö†Ô∏è  {endpoint.missing_components[0]}")

                if len(endpoints) > 5:
                    print(f"    ... –∏ –µ—â—ë {len(endpoints) - 5} —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤")

    if report.endpoints_by_tag:
        print(f"\nüè∑Ô∏è  –ü–û–ö–†–´–¢–ò–ï –î–û–ú–ï–ù–û–í:")
        for tag, endpoints in sorted(report.endpoints_by_tag.items()):
            implemented_in_tag = sum(1 for e in endpoints if e.status == ImplementationStatus.FULLY_IMPLEMENTED)
            total_in_tag = len(endpoints)
            coverage = (implemented_in_tag / total_in_tag) * 100 if total_in_tag > 0 else 0

            status_icon = "‚úÖ" if coverage == 100 else "‚ö†Ô∏è" if coverage >= 50 else "‚ùå"
            print(f"  {status_icon} {tag.title()}: {implemented_in_tag}/{total_in_tag} ({coverage:.1f}%)")

    if report.critical_missing_features:
        print(f"\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
        for feature in report.critical_missing_features:
            print(f"  ‚Ä¢ {feature}")

    if report.recommendations:
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ò –ü–†–ò–û–†–ò–¢–ï–¢–´:")
        for rec in report.recommendations:
            print(f"  ‚Ä¢ {rec}")

    print(f"\n" + "="*90)
    print("üîç –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –î–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–º. business_logic_report.json")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    project_root = Path(__file__).parent.parent

    checker = BusinessLogicChecker(project_root)
    report = checker.analyze_business_logic()

    print_report(report)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –≤ JSON
    report_data = {
        'total_endpoints': report.total_endpoints,
        'implemented_endpoints': report.implemented_endpoints,
        'mock_endpoints': report.mock_endpoints,
        'not_implemented_endpoints': report.not_implemented_endpoints,
        'partially_implemented_endpoints': report.partially_implemented_endpoints,
        'critical_missing_features': report.critical_missing_features,
        'recommendations': report.recommendations,
        'endpoints_by_status': {
            status: [
                {
                    'path': e.path,
                    'method': e.method,
                    'tags': e.tags,
                    'route_file': e.route_file,
                    'mock_patterns': e.mock_patterns,
                    'missing_components': e.missing_components
                } for e in endpoints
            ] for status, endpoints in report.endpoints_by_status.items()
        }
    }

    with open(project_root / 'business_logic_report.json', 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)

    print("üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ business_logic_report.json")


if __name__ == "__main__":
    main()
